{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huggingface_Sentence_transformer_ classify_questions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Huggingface_transformers_course/blob/main/Huggingface_Sentence_transformer__classify_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNOStrV0FmiC"
      },
      "source": [
        "##  Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8gq4t3d6uKU",
        "outputId": "a8f1055f-b9d3-4b9c-9ff1-bf31827e7a30"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 42.6MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnh3kiLKCBJg"
      },
      "source": [
        "## sentence-transformers/bert-base-nli-mean-tokens\n",
        "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE9BPl7177-1",
        "outputId": "a01ef565-68b8-4866-c27c-5d75169a8d5a"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/fd/8a81047bbd9fa134a3f27e12937d2a487bd49d353a038916a5d7ed4e5543/sentence-transformers-2.0.0.tar.gz (85kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.8.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.6.0)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.1)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-cp37-none-any.whl size=126711 sha256=5857eaa2c81b1f3bc77080057117d032e35fe24a025d9a2173feed8367fbb352\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/d2/98/d191289a877a34c68aa67e05179521e060f96394a3e9336be6\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3SoIoJ4MSUH"
      },
      "source": [
        "## Sentence Transformers -Distilbert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCaDctUHNezG"
      },
      "source": [
        "## Read Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dZ9l2_OdG0h",
        "outputId": "623864f0-a5a5-4c8a-c0c5-c7860c3eed87"
      },
      "source": [
        "!wget \"https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\"  -O newfile.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-11 16:49:28--  https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
            "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
            "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335858 (328K)\n",
            "Saving to: ‘newfile.txt’\n",
            "\n",
            "newfile.txt         100%[===================>] 327.99K  1.01MB/s    in 0.3s    \n",
            "\n",
            "2021-07-11 16:49:29 (1.01 MB/s) - ‘newfile.txt’ saved [335858/335858]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUwSETQ8Hskr"
      },
      "source": [
        "## Seggregate Label and Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_L-NjKLdRWQ"
      },
      "source": [
        "label = []\n",
        "question = []\n",
        "with open(\"/content/newfile.txt\",\"r\",encoding=\"ISO-8859-1\") as f:\n",
        "  for line in f.readlines():\n",
        "    text = line.split(\":\")\n",
        "    label.append(text[0])\n",
        "    question.append(text[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR6Ve1T_Hz9I"
      },
      "source": [
        "## Get the data into DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF02LmvhfAlZ"
      },
      "source": [
        "train = pd.DataFrame({'Question':question,'Label':label})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "d-IzGSBYfSEa",
        "outputId": "134a4a13-0c1f-4247-c9c2-94d08f8ca02e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>manner How did serfdom develop in and then lea...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cremat What films featured the character Popey...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>manner How can I find a list of celebrities ' ...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>animal What fowl grabs the spotlight after the...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>exp What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question Label\n",
              "0  manner How did serfdom develop in and then lea...  DESC\n",
              "1  cremat What films featured the character Popey...  ENTY\n",
              "2  manner How can I find a list of celebrities ' ...  DESC\n",
              "3  animal What fowl grabs the spotlight after the...  ENTY\n",
              "4              exp What is the full form of .com ?\\n  ABBR"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH061kx7Nrsk"
      },
      "source": [
        "## Using Transformer Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BixZRivPiIpB",
        "outputId": "4171f1d2-91f5-4700-b429-7d0c2ac30326"
      },
      "source": [
        "model = SentenceTransformer('sentence-transformers/distilbert-base-nli-mean-tokens')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.2805133  -0.47905654 -0.07459314 ... -0.6903942   0.65552545\n",
            "   0.4299319 ]\n",
            " [ 0.05076515 -0.2315884   0.44918177 ... -0.9458779   0.58218247\n",
            "   0.16936484]\n",
            " [ 0.16578268  0.08628527  0.99605757 ... -1.4010975  -0.16692434\n",
            "  -0.66698927]\n",
            " ...\n",
            " [-0.4809268  -0.33031234  0.902013   ... -0.7185601   0.3793425\n",
            "  -0.61258334]\n",
            " [ 0.16263308  0.17402235  0.30849615 ... -0.4745843   0.4362693\n",
            "  -0.6093792 ]\n",
            " [-0.23205915 -0.5019506  -0.1751888  ... -0.3825056   0.41391864\n",
            "  -0.66173697]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qU0Gr-MJ6n6"
      },
      "source": [
        "* The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2sNRHy4gi_n"
      },
      "source": [
        "train_vector = pd.DataFrame(np.array(sentence_embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "9LEmEN8XgxTH",
        "outputId": "8bb4f0ee-e64b-469d-e72b-a375c529ffab"
      },
      "source": [
        "train_vector.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.280513</td>\n",
              "      <td>-0.479056</td>\n",
              "      <td>-0.074593</td>\n",
              "      <td>-1.078832</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>-0.304827</td>\n",
              "      <td>0.710984</td>\n",
              "      <td>0.278826</td>\n",
              "      <td>0.129273</td>\n",
              "      <td>0.484495</td>\n",
              "      <td>0.194379</td>\n",
              "      <td>0.099252</td>\n",
              "      <td>0.048627</td>\n",
              "      <td>0.641369</td>\n",
              "      <td>0.453775</td>\n",
              "      <td>-0.550658</td>\n",
              "      <td>-0.685677</td>\n",
              "      <td>0.614255</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.382198</td>\n",
              "      <td>-0.034111</td>\n",
              "      <td>0.072872</td>\n",
              "      <td>0.070514</td>\n",
              "      <td>-0.182452</td>\n",
              "      <td>-0.672063</td>\n",
              "      <td>-0.203226</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>-0.494412</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.394312</td>\n",
              "      <td>0.036819</td>\n",
              "      <td>0.289581</td>\n",
              "      <td>0.572028</td>\n",
              "      <td>0.346302</td>\n",
              "      <td>-0.048939</td>\n",
              "      <td>0.285914</td>\n",
              "      <td>0.699641</td>\n",
              "      <td>0.078200</td>\n",
              "      <td>-0.658135</td>\n",
              "      <td>-0.720307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032483</td>\n",
              "      <td>-1.037481</td>\n",
              "      <td>-0.430439</td>\n",
              "      <td>0.345353</td>\n",
              "      <td>-0.443688</td>\n",
              "      <td>0.326153</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.017737</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.084457</td>\n",
              "      <td>-0.220593</td>\n",
              "      <td>-0.326400</td>\n",
              "      <td>0.109498</td>\n",
              "      <td>-0.313511</td>\n",
              "      <td>0.126476</td>\n",
              "      <td>-1.023944</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.276654</td>\n",
              "      <td>0.090974</td>\n",
              "      <td>-0.871338</td>\n",
              "      <td>0.066085</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.710252</td>\n",
              "      <td>0.815904</td>\n",
              "      <td>0.116723</td>\n",
              "      <td>-0.763052</td>\n",
              "      <td>-0.191135</td>\n",
              "      <td>-0.117061</td>\n",
              "      <td>-0.917495</td>\n",
              "      <td>0.238745</td>\n",
              "      <td>-0.721925</td>\n",
              "      <td>-0.708831</td>\n",
              "      <td>0.919505</td>\n",
              "      <td>0.014720</td>\n",
              "      <td>-0.218466</td>\n",
              "      <td>-0.708000</td>\n",
              "      <td>-0.060461</td>\n",
              "      <td>-0.690395</td>\n",
              "      <td>0.655526</td>\n",
              "      <td>0.429932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050765</td>\n",
              "      <td>-0.231588</td>\n",
              "      <td>0.449181</td>\n",
              "      <td>-0.434118</td>\n",
              "      <td>-0.437005</td>\n",
              "      <td>-0.025377</td>\n",
              "      <td>0.901858</td>\n",
              "      <td>0.299692</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.363240</td>\n",
              "      <td>0.813872</td>\n",
              "      <td>-0.242552</td>\n",
              "      <td>-0.046876</td>\n",
              "      <td>0.664556</td>\n",
              "      <td>0.063658</td>\n",
              "      <td>-0.778084</td>\n",
              "      <td>-0.464535</td>\n",
              "      <td>0.818348</td>\n",
              "      <td>0.217839</td>\n",
              "      <td>-0.682175</td>\n",
              "      <td>-0.048325</td>\n",
              "      <td>0.305596</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>-0.105053</td>\n",
              "      <td>-0.850086</td>\n",
              "      <td>-0.180318</td>\n",
              "      <td>0.599912</td>\n",
              "      <td>-0.693823</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>0.129673</td>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.366444</td>\n",
              "      <td>-0.351863</td>\n",
              "      <td>0.442381</td>\n",
              "      <td>0.333915</td>\n",
              "      <td>-0.367255</td>\n",
              "      <td>1.370850</td>\n",
              "      <td>-0.371236</td>\n",
              "      <td>-0.394274</td>\n",
              "      <td>0.127976</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.759870</td>\n",
              "      <td>-0.319705</td>\n",
              "      <td>-0.320549</td>\n",
              "      <td>0.269263</td>\n",
              "      <td>-0.234702</td>\n",
              "      <td>0.203369</td>\n",
              "      <td>0.363199</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.343576</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>-0.211596</td>\n",
              "      <td>0.346223</td>\n",
              "      <td>-0.544377</td>\n",
              "      <td>0.259784</td>\n",
              "      <td>-0.261309</td>\n",
              "      <td>-0.354508</td>\n",
              "      <td>-0.033133</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>0.176840</td>\n",
              "      <td>-0.155799</td>\n",
              "      <td>-1.046834</td>\n",
              "      <td>-0.140346</td>\n",
              "      <td>0.822187</td>\n",
              "      <td>1.090696</td>\n",
              "      <td>-0.127105</td>\n",
              "      <td>-1.281975</td>\n",
              "      <td>0.121476</td>\n",
              "      <td>-0.035387</td>\n",
              "      <td>-1.036540</td>\n",
              "      <td>-0.455563</td>\n",
              "      <td>-1.028529</td>\n",
              "      <td>-0.167688</td>\n",
              "      <td>-0.617333</td>\n",
              "      <td>-0.128335</td>\n",
              "      <td>-0.154140</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>-0.945878</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.169365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165783</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.996058</td>\n",
              "      <td>-0.007494</td>\n",
              "      <td>-0.062556</td>\n",
              "      <td>-0.447119</td>\n",
              "      <td>1.157737</td>\n",
              "      <td>-0.594609</td>\n",
              "      <td>-0.278916</td>\n",
              "      <td>0.288760</td>\n",
              "      <td>-0.755688</td>\n",
              "      <td>0.518913</td>\n",
              "      <td>-0.589019</td>\n",
              "      <td>-0.218036</td>\n",
              "      <td>-0.299750</td>\n",
              "      <td>-0.588890</td>\n",
              "      <td>-1.044726</td>\n",
              "      <td>0.417887</td>\n",
              "      <td>-0.516429</td>\n",
              "      <td>-0.688118</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>0.023603</td>\n",
              "      <td>-0.186256</td>\n",
              "      <td>0.847153</td>\n",
              "      <td>-0.451656</td>\n",
              "      <td>0.414896</td>\n",
              "      <td>0.153553</td>\n",
              "      <td>-0.524881</td>\n",
              "      <td>0.480987</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.525045</td>\n",
              "      <td>0.589052</td>\n",
              "      <td>-0.483123</td>\n",
              "      <td>0.143384</td>\n",
              "      <td>0.049669</td>\n",
              "      <td>-0.625911</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>-0.494312</td>\n",
              "      <td>0.039376</td>\n",
              "      <td>-0.539757</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.288382</td>\n",
              "      <td>0.158904</td>\n",
              "      <td>-0.675779</td>\n",
              "      <td>-0.603539</td>\n",
              "      <td>-0.569769</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.707026</td>\n",
              "      <td>0.829515</td>\n",
              "      <td>-0.109335</td>\n",
              "      <td>0.677547</td>\n",
              "      <td>0.197821</td>\n",
              "      <td>0.223960</td>\n",
              "      <td>-0.297395</td>\n",
              "      <td>-0.826129</td>\n",
              "      <td>-0.965579</td>\n",
              "      <td>-0.218842</td>\n",
              "      <td>1.487623</td>\n",
              "      <td>-0.247484</td>\n",
              "      <td>-0.609410</td>\n",
              "      <td>-0.065344</td>\n",
              "      <td>-0.464756</td>\n",
              "      <td>-0.134924</td>\n",
              "      <td>1.308985</td>\n",
              "      <td>0.461914</td>\n",
              "      <td>-0.319942</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.672880</td>\n",
              "      <td>0.423251</td>\n",
              "      <td>-1.299873</td>\n",
              "      <td>-0.380740</td>\n",
              "      <td>-1.354729</td>\n",
              "      <td>-0.239816</td>\n",
              "      <td>-0.171939</td>\n",
              "      <td>0.529478</td>\n",
              "      <td>-0.135893</td>\n",
              "      <td>1.097948</td>\n",
              "      <td>-0.018600</td>\n",
              "      <td>-1.401098</td>\n",
              "      <td>-0.166925</td>\n",
              "      <td>-0.666990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178117</td>\n",
              "      <td>-0.473958</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>-1.291486</td>\n",
              "      <td>-0.028840</td>\n",
              "      <td>0.348842</td>\n",
              "      <td>-0.046128</td>\n",
              "      <td>0.052367</td>\n",
              "      <td>-0.436607</td>\n",
              "      <td>1.082325</td>\n",
              "      <td>1.379477</td>\n",
              "      <td>0.269813</td>\n",
              "      <td>-0.224945</td>\n",
              "      <td>0.555075</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>-1.012060</td>\n",
              "      <td>-0.139680</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>-0.556999</td>\n",
              "      <td>-0.128182</td>\n",
              "      <td>0.313684</td>\n",
              "      <td>-0.397970</td>\n",
              "      <td>0.625162</td>\n",
              "      <td>-1.139045</td>\n",
              "      <td>0.605110</td>\n",
              "      <td>0.438818</td>\n",
              "      <td>-0.294600</td>\n",
              "      <td>-0.015436</td>\n",
              "      <td>-0.200387</td>\n",
              "      <td>-0.028176</td>\n",
              "      <td>0.543886</td>\n",
              "      <td>-0.501193</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>-0.207827</td>\n",
              "      <td>-0.185351</td>\n",
              "      <td>0.511595</td>\n",
              "      <td>-0.588324</td>\n",
              "      <td>0.523014</td>\n",
              "      <td>-0.696837</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.323599</td>\n",
              "      <td>-0.134632</td>\n",
              "      <td>-0.420600</td>\n",
              "      <td>-0.185516</td>\n",
              "      <td>-0.183404</td>\n",
              "      <td>0.793519</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.518475</td>\n",
              "      <td>0.655392</td>\n",
              "      <td>0.389528</td>\n",
              "      <td>-0.159402</td>\n",
              "      <td>0.155687</td>\n",
              "      <td>-0.318773</td>\n",
              "      <td>-0.182897</td>\n",
              "      <td>-0.584351</td>\n",
              "      <td>-1.437036</td>\n",
              "      <td>0.627801</td>\n",
              "      <td>0.532542</td>\n",
              "      <td>0.662939</td>\n",
              "      <td>0.678888</td>\n",
              "      <td>-0.622288</td>\n",
              "      <td>0.319153</td>\n",
              "      <td>0.996853</td>\n",
              "      <td>0.696456</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>-0.387256</td>\n",
              "      <td>0.541325</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>-0.789448</td>\n",
              "      <td>-0.599024</td>\n",
              "      <td>-0.941752</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>-0.710274</td>\n",
              "      <td>0.030269</td>\n",
              "      <td>0.281970</td>\n",
              "      <td>0.180029</td>\n",
              "      <td>0.274251</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>1.007164</td>\n",
              "      <td>-0.209413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.341517</td>\n",
              "      <td>-0.614351</td>\n",
              "      <td>0.075421</td>\n",
              "      <td>-0.381870</td>\n",
              "      <td>-0.037141</td>\n",
              "      <td>-0.639595</td>\n",
              "      <td>1.047396</td>\n",
              "      <td>1.109776</td>\n",
              "      <td>-0.500967</td>\n",
              "      <td>-0.308550</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.180812</td>\n",
              "      <td>0.402919</td>\n",
              "      <td>0.446856</td>\n",
              "      <td>-0.506134</td>\n",
              "      <td>-0.852798</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>-0.568851</td>\n",
              "      <td>-0.948410</td>\n",
              "      <td>0.342488</td>\n",
              "      <td>-0.257154</td>\n",
              "      <td>-0.041045</td>\n",
              "      <td>1.054365</td>\n",
              "      <td>0.182190</td>\n",
              "      <td>0.183331</td>\n",
              "      <td>0.685496</td>\n",
              "      <td>-0.191476</td>\n",
              "      <td>-0.196328</td>\n",
              "      <td>-0.376523</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>-0.232624</td>\n",
              "      <td>-0.124186</td>\n",
              "      <td>0.408084</td>\n",
              "      <td>0.532742</td>\n",
              "      <td>-0.697111</td>\n",
              "      <td>-0.076796</td>\n",
              "      <td>-0.269128</td>\n",
              "      <td>-0.596582</td>\n",
              "      <td>-0.246367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.935546</td>\n",
              "      <td>0.314507</td>\n",
              "      <td>-0.171532</td>\n",
              "      <td>-0.507654</td>\n",
              "      <td>-0.372031</td>\n",
              "      <td>0.384393</td>\n",
              "      <td>-0.427786</td>\n",
              "      <td>-0.062957</td>\n",
              "      <td>0.381885</td>\n",
              "      <td>-0.210031</td>\n",
              "      <td>-0.373228</td>\n",
              "      <td>0.138790</td>\n",
              "      <td>-0.295719</td>\n",
              "      <td>-0.431427</td>\n",
              "      <td>-0.521123</td>\n",
              "      <td>0.406643</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>-0.539807</td>\n",
              "      <td>-0.619525</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>-0.941711</td>\n",
              "      <td>-0.363686</td>\n",
              "      <td>0.716169</td>\n",
              "      <td>-0.360151</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.696636</td>\n",
              "      <td>-0.872138</td>\n",
              "      <td>0.198449</td>\n",
              "      <td>-0.777934</td>\n",
              "      <td>0.183854</td>\n",
              "      <td>-0.967491</td>\n",
              "      <td>-0.433642</td>\n",
              "      <td>-0.074372</td>\n",
              "      <td>-0.851413</td>\n",
              "      <td>-0.311539</td>\n",
              "      <td>0.008006</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.726386</td>\n",
              "      <td>0.608123</td>\n",
              "      <td>-0.062077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       765       766       767\n",
              "0 -1.280513 -0.479056 -0.074593  ... -0.690395  0.655526  0.429932\n",
              "1  0.050765 -0.231588  0.449181  ... -0.945878  0.582182  0.169365\n",
              "2  0.165783  0.086285  0.996058  ... -1.401098 -0.166925 -0.666990\n",
              "3 -0.178117 -0.473958  0.048356  ... -0.035899  1.007164 -0.209413\n",
              "4 -0.341517 -0.614351  0.075421  ... -0.726386  0.608123 -0.062077\n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oJat2zAIAfs"
      },
      "source": [
        "## Concat genereated word Vector aloing with the original text and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY3sMlPhHu3"
      },
      "source": [
        "final_train = pd.concat((train_vector,train),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "BzI5BguFhba9",
        "outputId": "4b12a2cc-f88e-4e1f-e180-cd1fcfaa82dd"
      },
      "source": [
        "final_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.280513</td>\n",
              "      <td>-0.479056</td>\n",
              "      <td>-0.074593</td>\n",
              "      <td>-1.078832</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>-0.304827</td>\n",
              "      <td>0.710984</td>\n",
              "      <td>0.278826</td>\n",
              "      <td>0.129273</td>\n",
              "      <td>0.484495</td>\n",
              "      <td>0.194379</td>\n",
              "      <td>0.099252</td>\n",
              "      <td>0.048627</td>\n",
              "      <td>0.641369</td>\n",
              "      <td>0.453775</td>\n",
              "      <td>-0.550658</td>\n",
              "      <td>-0.685677</td>\n",
              "      <td>0.614255</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.382198</td>\n",
              "      <td>-0.034111</td>\n",
              "      <td>0.072872</td>\n",
              "      <td>0.070514</td>\n",
              "      <td>-0.182452</td>\n",
              "      <td>-0.672063</td>\n",
              "      <td>-0.203226</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>-0.494412</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.394312</td>\n",
              "      <td>0.036819</td>\n",
              "      <td>0.289581</td>\n",
              "      <td>0.572028</td>\n",
              "      <td>0.346302</td>\n",
              "      <td>-0.048939</td>\n",
              "      <td>0.285914</td>\n",
              "      <td>0.699641</td>\n",
              "      <td>0.078200</td>\n",
              "      <td>-0.658135</td>\n",
              "      <td>-0.720307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.430439</td>\n",
              "      <td>0.345353</td>\n",
              "      <td>-0.443688</td>\n",
              "      <td>0.326153</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.017737</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.084457</td>\n",
              "      <td>-0.220593</td>\n",
              "      <td>-0.326400</td>\n",
              "      <td>0.109498</td>\n",
              "      <td>-0.313511</td>\n",
              "      <td>0.126476</td>\n",
              "      <td>-1.023944</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.276654</td>\n",
              "      <td>0.090974</td>\n",
              "      <td>-0.871338</td>\n",
              "      <td>0.066085</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.710252</td>\n",
              "      <td>0.815904</td>\n",
              "      <td>0.116723</td>\n",
              "      <td>-0.763052</td>\n",
              "      <td>-0.191135</td>\n",
              "      <td>-0.117061</td>\n",
              "      <td>-0.917495</td>\n",
              "      <td>0.238745</td>\n",
              "      <td>-0.721925</td>\n",
              "      <td>-0.708831</td>\n",
              "      <td>0.919505</td>\n",
              "      <td>0.014720</td>\n",
              "      <td>-0.218466</td>\n",
              "      <td>-0.708000</td>\n",
              "      <td>-0.060461</td>\n",
              "      <td>-0.690395</td>\n",
              "      <td>0.655526</td>\n",
              "      <td>0.429932</td>\n",
              "      <td>manner How did serfdom develop in and then lea...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050765</td>\n",
              "      <td>-0.231588</td>\n",
              "      <td>0.449181</td>\n",
              "      <td>-0.434118</td>\n",
              "      <td>-0.437005</td>\n",
              "      <td>-0.025377</td>\n",
              "      <td>0.901858</td>\n",
              "      <td>0.299692</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.363240</td>\n",
              "      <td>0.813872</td>\n",
              "      <td>-0.242552</td>\n",
              "      <td>-0.046876</td>\n",
              "      <td>0.664556</td>\n",
              "      <td>0.063658</td>\n",
              "      <td>-0.778084</td>\n",
              "      <td>-0.464535</td>\n",
              "      <td>0.818348</td>\n",
              "      <td>0.217839</td>\n",
              "      <td>-0.682175</td>\n",
              "      <td>-0.048325</td>\n",
              "      <td>0.305596</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>-0.105053</td>\n",
              "      <td>-0.850086</td>\n",
              "      <td>-0.180318</td>\n",
              "      <td>0.599912</td>\n",
              "      <td>-0.693823</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>0.129673</td>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.366444</td>\n",
              "      <td>-0.351863</td>\n",
              "      <td>0.442381</td>\n",
              "      <td>0.333915</td>\n",
              "      <td>-0.367255</td>\n",
              "      <td>1.370850</td>\n",
              "      <td>-0.371236</td>\n",
              "      <td>-0.394274</td>\n",
              "      <td>0.127976</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.320549</td>\n",
              "      <td>0.269263</td>\n",
              "      <td>-0.234702</td>\n",
              "      <td>0.203369</td>\n",
              "      <td>0.363199</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.343576</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>-0.211596</td>\n",
              "      <td>0.346223</td>\n",
              "      <td>-0.544377</td>\n",
              "      <td>0.259784</td>\n",
              "      <td>-0.261309</td>\n",
              "      <td>-0.354508</td>\n",
              "      <td>-0.033133</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>0.176840</td>\n",
              "      <td>-0.155799</td>\n",
              "      <td>-1.046834</td>\n",
              "      <td>-0.140346</td>\n",
              "      <td>0.822187</td>\n",
              "      <td>1.090696</td>\n",
              "      <td>-0.127105</td>\n",
              "      <td>-1.281975</td>\n",
              "      <td>0.121476</td>\n",
              "      <td>-0.035387</td>\n",
              "      <td>-1.036540</td>\n",
              "      <td>-0.455563</td>\n",
              "      <td>-1.028529</td>\n",
              "      <td>-0.167688</td>\n",
              "      <td>-0.617333</td>\n",
              "      <td>-0.128335</td>\n",
              "      <td>-0.154140</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>-0.945878</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.169365</td>\n",
              "      <td>cremat What films featured the character Popey...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165783</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.996058</td>\n",
              "      <td>-0.007494</td>\n",
              "      <td>-0.062556</td>\n",
              "      <td>-0.447119</td>\n",
              "      <td>1.157737</td>\n",
              "      <td>-0.594609</td>\n",
              "      <td>-0.278916</td>\n",
              "      <td>0.288760</td>\n",
              "      <td>-0.755688</td>\n",
              "      <td>0.518913</td>\n",
              "      <td>-0.589019</td>\n",
              "      <td>-0.218036</td>\n",
              "      <td>-0.299750</td>\n",
              "      <td>-0.588890</td>\n",
              "      <td>-1.044726</td>\n",
              "      <td>0.417887</td>\n",
              "      <td>-0.516429</td>\n",
              "      <td>-0.688118</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>0.023603</td>\n",
              "      <td>-0.186256</td>\n",
              "      <td>0.847153</td>\n",
              "      <td>-0.451656</td>\n",
              "      <td>0.414896</td>\n",
              "      <td>0.153553</td>\n",
              "      <td>-0.524881</td>\n",
              "      <td>0.480987</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.525045</td>\n",
              "      <td>0.589052</td>\n",
              "      <td>-0.483123</td>\n",
              "      <td>0.143384</td>\n",
              "      <td>0.049669</td>\n",
              "      <td>-0.625911</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>-0.494312</td>\n",
              "      <td>0.039376</td>\n",
              "      <td>-0.539757</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.675779</td>\n",
              "      <td>-0.603539</td>\n",
              "      <td>-0.569769</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.707026</td>\n",
              "      <td>0.829515</td>\n",
              "      <td>-0.109335</td>\n",
              "      <td>0.677547</td>\n",
              "      <td>0.197821</td>\n",
              "      <td>0.223960</td>\n",
              "      <td>-0.297395</td>\n",
              "      <td>-0.826129</td>\n",
              "      <td>-0.965579</td>\n",
              "      <td>-0.218842</td>\n",
              "      <td>1.487623</td>\n",
              "      <td>-0.247484</td>\n",
              "      <td>-0.609410</td>\n",
              "      <td>-0.065344</td>\n",
              "      <td>-0.464756</td>\n",
              "      <td>-0.134924</td>\n",
              "      <td>1.308985</td>\n",
              "      <td>0.461914</td>\n",
              "      <td>-0.319942</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.672880</td>\n",
              "      <td>0.423251</td>\n",
              "      <td>-1.299873</td>\n",
              "      <td>-0.380740</td>\n",
              "      <td>-1.354729</td>\n",
              "      <td>-0.239816</td>\n",
              "      <td>-0.171939</td>\n",
              "      <td>0.529478</td>\n",
              "      <td>-0.135893</td>\n",
              "      <td>1.097948</td>\n",
              "      <td>-0.018600</td>\n",
              "      <td>-1.401098</td>\n",
              "      <td>-0.166925</td>\n",
              "      <td>-0.666990</td>\n",
              "      <td>manner How can I find a list of celebrities ' ...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178117</td>\n",
              "      <td>-0.473958</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>-1.291486</td>\n",
              "      <td>-0.028840</td>\n",
              "      <td>0.348842</td>\n",
              "      <td>-0.046128</td>\n",
              "      <td>0.052367</td>\n",
              "      <td>-0.436607</td>\n",
              "      <td>1.082325</td>\n",
              "      <td>1.379477</td>\n",
              "      <td>0.269813</td>\n",
              "      <td>-0.224945</td>\n",
              "      <td>0.555075</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>-1.012060</td>\n",
              "      <td>-0.139680</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>-0.556999</td>\n",
              "      <td>-0.128182</td>\n",
              "      <td>0.313684</td>\n",
              "      <td>-0.397970</td>\n",
              "      <td>0.625162</td>\n",
              "      <td>-1.139045</td>\n",
              "      <td>0.605110</td>\n",
              "      <td>0.438818</td>\n",
              "      <td>-0.294600</td>\n",
              "      <td>-0.015436</td>\n",
              "      <td>-0.200387</td>\n",
              "      <td>-0.028176</td>\n",
              "      <td>0.543886</td>\n",
              "      <td>-0.501193</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>-0.207827</td>\n",
              "      <td>-0.185351</td>\n",
              "      <td>0.511595</td>\n",
              "      <td>-0.588324</td>\n",
              "      <td>0.523014</td>\n",
              "      <td>-0.696837</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.420600</td>\n",
              "      <td>-0.185516</td>\n",
              "      <td>-0.183404</td>\n",
              "      <td>0.793519</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.518475</td>\n",
              "      <td>0.655392</td>\n",
              "      <td>0.389528</td>\n",
              "      <td>-0.159402</td>\n",
              "      <td>0.155687</td>\n",
              "      <td>-0.318773</td>\n",
              "      <td>-0.182897</td>\n",
              "      <td>-0.584351</td>\n",
              "      <td>-1.437036</td>\n",
              "      <td>0.627801</td>\n",
              "      <td>0.532542</td>\n",
              "      <td>0.662939</td>\n",
              "      <td>0.678888</td>\n",
              "      <td>-0.622288</td>\n",
              "      <td>0.319153</td>\n",
              "      <td>0.996853</td>\n",
              "      <td>0.696456</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>-0.387256</td>\n",
              "      <td>0.541325</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>-0.789448</td>\n",
              "      <td>-0.599024</td>\n",
              "      <td>-0.941752</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>-0.710274</td>\n",
              "      <td>0.030269</td>\n",
              "      <td>0.281970</td>\n",
              "      <td>0.180029</td>\n",
              "      <td>0.274251</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>1.007164</td>\n",
              "      <td>-0.209413</td>\n",
              "      <td>animal What fowl grabs the spotlight after the...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.341517</td>\n",
              "      <td>-0.614351</td>\n",
              "      <td>0.075421</td>\n",
              "      <td>-0.381870</td>\n",
              "      <td>-0.037141</td>\n",
              "      <td>-0.639595</td>\n",
              "      <td>1.047396</td>\n",
              "      <td>1.109776</td>\n",
              "      <td>-0.500967</td>\n",
              "      <td>-0.308550</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.180812</td>\n",
              "      <td>0.402919</td>\n",
              "      <td>0.446856</td>\n",
              "      <td>-0.506134</td>\n",
              "      <td>-0.852798</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>-0.568851</td>\n",
              "      <td>-0.948410</td>\n",
              "      <td>0.342488</td>\n",
              "      <td>-0.257154</td>\n",
              "      <td>-0.041045</td>\n",
              "      <td>1.054365</td>\n",
              "      <td>0.182190</td>\n",
              "      <td>0.183331</td>\n",
              "      <td>0.685496</td>\n",
              "      <td>-0.191476</td>\n",
              "      <td>-0.196328</td>\n",
              "      <td>-0.376523</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>-0.232624</td>\n",
              "      <td>-0.124186</td>\n",
              "      <td>0.408084</td>\n",
              "      <td>0.532742</td>\n",
              "      <td>-0.697111</td>\n",
              "      <td>-0.076796</td>\n",
              "      <td>-0.269128</td>\n",
              "      <td>-0.596582</td>\n",
              "      <td>-0.246367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.171532</td>\n",
              "      <td>-0.507654</td>\n",
              "      <td>-0.372031</td>\n",
              "      <td>0.384393</td>\n",
              "      <td>-0.427786</td>\n",
              "      <td>-0.062957</td>\n",
              "      <td>0.381885</td>\n",
              "      <td>-0.210031</td>\n",
              "      <td>-0.373228</td>\n",
              "      <td>0.138790</td>\n",
              "      <td>-0.295719</td>\n",
              "      <td>-0.431427</td>\n",
              "      <td>-0.521123</td>\n",
              "      <td>0.406643</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>-0.539807</td>\n",
              "      <td>-0.619525</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>-0.941711</td>\n",
              "      <td>-0.363686</td>\n",
              "      <td>0.716169</td>\n",
              "      <td>-0.360151</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.696636</td>\n",
              "      <td>-0.872138</td>\n",
              "      <td>0.198449</td>\n",
              "      <td>-0.777934</td>\n",
              "      <td>0.183854</td>\n",
              "      <td>-0.967491</td>\n",
              "      <td>-0.433642</td>\n",
              "      <td>-0.074372</td>\n",
              "      <td>-0.851413</td>\n",
              "      <td>-0.311539</td>\n",
              "      <td>0.008006</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.726386</td>\n",
              "      <td>0.608123</td>\n",
              "      <td>-0.062077</td>\n",
              "      <td>exp What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 770 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1  ...                                           Question  Label\n",
              "0 -1.280513 -0.479056  ...  manner How did serfdom develop in and then lea...   DESC\n",
              "1  0.050765 -0.231588  ...  cremat What films featured the character Popey...   ENTY\n",
              "2  0.165783  0.086285  ...  manner How can I find a list of celebrities ' ...   DESC\n",
              "3 -0.178117 -0.473958  ...  animal What fowl grabs the spotlight after the...   ENTY\n",
              "4 -0.341517 -0.614351  ...              exp What is the full form of .com ?\\n   ABBR\n",
              "\n",
              "[5 rows x 770 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXuBWGH6JSte"
      },
      "source": [
        "## Visualize the distribution of the Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "AgrvAZ-qhj5_",
        "outputId": "9f61926e-b0f8-4ebd-aa29-beec3c024db9"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(x='Label',data=final_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f352173a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG6_qHVNoReY"
      },
      "source": [
        "## Import Machine Learning Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtmM6ZbioU3j"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQxJMd-AJaCN"
      },
      "source": [
        "## Label encoding the target (Label)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV59K9NopUCr",
        "outputId": "873a4bf3-9706-4be7-d64b-c5d1cebe157f"
      },
      "source": [
        "lb = LabelEncoder()\n",
        "lbl_encoded = lb.fit_transform(final_train['Label'])\n",
        "lb.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "hI3i7nRrtwRr",
        "outputId": "f6285296-da5a-49ff-8ded-6f7c14a28907"
      },
      "source": [
        "final_train['Label_enc'] = lbl_encoded \n",
        "final_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.280513</td>\n",
              "      <td>-0.479056</td>\n",
              "      <td>-0.074593</td>\n",
              "      <td>-1.078832</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>-0.304827</td>\n",
              "      <td>0.710984</td>\n",
              "      <td>0.278826</td>\n",
              "      <td>0.129273</td>\n",
              "      <td>0.484495</td>\n",
              "      <td>0.194379</td>\n",
              "      <td>0.099252</td>\n",
              "      <td>0.048627</td>\n",
              "      <td>0.641369</td>\n",
              "      <td>0.453775</td>\n",
              "      <td>-0.550658</td>\n",
              "      <td>-0.685677</td>\n",
              "      <td>0.614255</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.382198</td>\n",
              "      <td>-0.034111</td>\n",
              "      <td>0.072872</td>\n",
              "      <td>0.070514</td>\n",
              "      <td>-0.182452</td>\n",
              "      <td>-0.672063</td>\n",
              "      <td>-0.203226</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>-0.494412</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.394312</td>\n",
              "      <td>0.036819</td>\n",
              "      <td>0.289581</td>\n",
              "      <td>0.572028</td>\n",
              "      <td>0.346302</td>\n",
              "      <td>-0.048939</td>\n",
              "      <td>0.285914</td>\n",
              "      <td>0.699641</td>\n",
              "      <td>0.078200</td>\n",
              "      <td>-0.658135</td>\n",
              "      <td>-0.720307</td>\n",
              "      <td>...</td>\n",
              "      <td>0.345353</td>\n",
              "      <td>-0.443688</td>\n",
              "      <td>0.326153</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.017737</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.084457</td>\n",
              "      <td>-0.220593</td>\n",
              "      <td>-0.326400</td>\n",
              "      <td>0.109498</td>\n",
              "      <td>-0.313511</td>\n",
              "      <td>0.126476</td>\n",
              "      <td>-1.023944</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.276654</td>\n",
              "      <td>0.090974</td>\n",
              "      <td>-0.871338</td>\n",
              "      <td>0.066085</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.710252</td>\n",
              "      <td>0.815904</td>\n",
              "      <td>0.116723</td>\n",
              "      <td>-0.763052</td>\n",
              "      <td>-0.191135</td>\n",
              "      <td>-0.117061</td>\n",
              "      <td>-0.917495</td>\n",
              "      <td>0.238745</td>\n",
              "      <td>-0.721925</td>\n",
              "      <td>-0.708831</td>\n",
              "      <td>0.919505</td>\n",
              "      <td>0.014720</td>\n",
              "      <td>-0.218466</td>\n",
              "      <td>-0.708000</td>\n",
              "      <td>-0.060461</td>\n",
              "      <td>-0.690395</td>\n",
              "      <td>0.655526</td>\n",
              "      <td>0.429932</td>\n",
              "      <td>manner How did serfdom develop in and then lea...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050765</td>\n",
              "      <td>-0.231588</td>\n",
              "      <td>0.449181</td>\n",
              "      <td>-0.434118</td>\n",
              "      <td>-0.437005</td>\n",
              "      <td>-0.025377</td>\n",
              "      <td>0.901858</td>\n",
              "      <td>0.299692</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.363240</td>\n",
              "      <td>0.813872</td>\n",
              "      <td>-0.242552</td>\n",
              "      <td>-0.046876</td>\n",
              "      <td>0.664556</td>\n",
              "      <td>0.063658</td>\n",
              "      <td>-0.778084</td>\n",
              "      <td>-0.464535</td>\n",
              "      <td>0.818348</td>\n",
              "      <td>0.217839</td>\n",
              "      <td>-0.682175</td>\n",
              "      <td>-0.048325</td>\n",
              "      <td>0.305596</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>-0.105053</td>\n",
              "      <td>-0.850086</td>\n",
              "      <td>-0.180318</td>\n",
              "      <td>0.599912</td>\n",
              "      <td>-0.693823</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>0.129673</td>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.366444</td>\n",
              "      <td>-0.351863</td>\n",
              "      <td>0.442381</td>\n",
              "      <td>0.333915</td>\n",
              "      <td>-0.367255</td>\n",
              "      <td>1.370850</td>\n",
              "      <td>-0.371236</td>\n",
              "      <td>-0.394274</td>\n",
              "      <td>0.127976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269263</td>\n",
              "      <td>-0.234702</td>\n",
              "      <td>0.203369</td>\n",
              "      <td>0.363199</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.343576</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>-0.211596</td>\n",
              "      <td>0.346223</td>\n",
              "      <td>-0.544377</td>\n",
              "      <td>0.259784</td>\n",
              "      <td>-0.261309</td>\n",
              "      <td>-0.354508</td>\n",
              "      <td>-0.033133</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>0.176840</td>\n",
              "      <td>-0.155799</td>\n",
              "      <td>-1.046834</td>\n",
              "      <td>-0.140346</td>\n",
              "      <td>0.822187</td>\n",
              "      <td>1.090696</td>\n",
              "      <td>-0.127105</td>\n",
              "      <td>-1.281975</td>\n",
              "      <td>0.121476</td>\n",
              "      <td>-0.035387</td>\n",
              "      <td>-1.036540</td>\n",
              "      <td>-0.455563</td>\n",
              "      <td>-1.028529</td>\n",
              "      <td>-0.167688</td>\n",
              "      <td>-0.617333</td>\n",
              "      <td>-0.128335</td>\n",
              "      <td>-0.154140</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>-0.945878</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.169365</td>\n",
              "      <td>cremat What films featured the character Popey...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165783</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.996058</td>\n",
              "      <td>-0.007494</td>\n",
              "      <td>-0.062556</td>\n",
              "      <td>-0.447119</td>\n",
              "      <td>1.157737</td>\n",
              "      <td>-0.594609</td>\n",
              "      <td>-0.278916</td>\n",
              "      <td>0.288760</td>\n",
              "      <td>-0.755688</td>\n",
              "      <td>0.518913</td>\n",
              "      <td>-0.589019</td>\n",
              "      <td>-0.218036</td>\n",
              "      <td>-0.299750</td>\n",
              "      <td>-0.588890</td>\n",
              "      <td>-1.044726</td>\n",
              "      <td>0.417887</td>\n",
              "      <td>-0.516429</td>\n",
              "      <td>-0.688118</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>0.023603</td>\n",
              "      <td>-0.186256</td>\n",
              "      <td>0.847153</td>\n",
              "      <td>-0.451656</td>\n",
              "      <td>0.414896</td>\n",
              "      <td>0.153553</td>\n",
              "      <td>-0.524881</td>\n",
              "      <td>0.480987</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.525045</td>\n",
              "      <td>0.589052</td>\n",
              "      <td>-0.483123</td>\n",
              "      <td>0.143384</td>\n",
              "      <td>0.049669</td>\n",
              "      <td>-0.625911</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>-0.494312</td>\n",
              "      <td>0.039376</td>\n",
              "      <td>-0.539757</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.603539</td>\n",
              "      <td>-0.569769</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.707026</td>\n",
              "      <td>0.829515</td>\n",
              "      <td>-0.109335</td>\n",
              "      <td>0.677547</td>\n",
              "      <td>0.197821</td>\n",
              "      <td>0.223960</td>\n",
              "      <td>-0.297395</td>\n",
              "      <td>-0.826129</td>\n",
              "      <td>-0.965579</td>\n",
              "      <td>-0.218842</td>\n",
              "      <td>1.487623</td>\n",
              "      <td>-0.247484</td>\n",
              "      <td>-0.609410</td>\n",
              "      <td>-0.065344</td>\n",
              "      <td>-0.464756</td>\n",
              "      <td>-0.134924</td>\n",
              "      <td>1.308985</td>\n",
              "      <td>0.461914</td>\n",
              "      <td>-0.319942</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.672880</td>\n",
              "      <td>0.423251</td>\n",
              "      <td>-1.299873</td>\n",
              "      <td>-0.380740</td>\n",
              "      <td>-1.354729</td>\n",
              "      <td>-0.239816</td>\n",
              "      <td>-0.171939</td>\n",
              "      <td>0.529478</td>\n",
              "      <td>-0.135893</td>\n",
              "      <td>1.097948</td>\n",
              "      <td>-0.018600</td>\n",
              "      <td>-1.401098</td>\n",
              "      <td>-0.166925</td>\n",
              "      <td>-0.666990</td>\n",
              "      <td>manner How can I find a list of celebrities ' ...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178117</td>\n",
              "      <td>-0.473958</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>-1.291486</td>\n",
              "      <td>-0.028840</td>\n",
              "      <td>0.348842</td>\n",
              "      <td>-0.046128</td>\n",
              "      <td>0.052367</td>\n",
              "      <td>-0.436607</td>\n",
              "      <td>1.082325</td>\n",
              "      <td>1.379477</td>\n",
              "      <td>0.269813</td>\n",
              "      <td>-0.224945</td>\n",
              "      <td>0.555075</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>-1.012060</td>\n",
              "      <td>-0.139680</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>-0.556999</td>\n",
              "      <td>-0.128182</td>\n",
              "      <td>0.313684</td>\n",
              "      <td>-0.397970</td>\n",
              "      <td>0.625162</td>\n",
              "      <td>-1.139045</td>\n",
              "      <td>0.605110</td>\n",
              "      <td>0.438818</td>\n",
              "      <td>-0.294600</td>\n",
              "      <td>-0.015436</td>\n",
              "      <td>-0.200387</td>\n",
              "      <td>-0.028176</td>\n",
              "      <td>0.543886</td>\n",
              "      <td>-0.501193</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>-0.207827</td>\n",
              "      <td>-0.185351</td>\n",
              "      <td>0.511595</td>\n",
              "      <td>-0.588324</td>\n",
              "      <td>0.523014</td>\n",
              "      <td>-0.696837</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.185516</td>\n",
              "      <td>-0.183404</td>\n",
              "      <td>0.793519</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.518475</td>\n",
              "      <td>0.655392</td>\n",
              "      <td>0.389528</td>\n",
              "      <td>-0.159402</td>\n",
              "      <td>0.155687</td>\n",
              "      <td>-0.318773</td>\n",
              "      <td>-0.182897</td>\n",
              "      <td>-0.584351</td>\n",
              "      <td>-1.437036</td>\n",
              "      <td>0.627801</td>\n",
              "      <td>0.532542</td>\n",
              "      <td>0.662939</td>\n",
              "      <td>0.678888</td>\n",
              "      <td>-0.622288</td>\n",
              "      <td>0.319153</td>\n",
              "      <td>0.996853</td>\n",
              "      <td>0.696456</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>-0.387256</td>\n",
              "      <td>0.541325</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>-0.789448</td>\n",
              "      <td>-0.599024</td>\n",
              "      <td>-0.941752</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>-0.710274</td>\n",
              "      <td>0.030269</td>\n",
              "      <td>0.281970</td>\n",
              "      <td>0.180029</td>\n",
              "      <td>0.274251</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>1.007164</td>\n",
              "      <td>-0.209413</td>\n",
              "      <td>animal What fowl grabs the spotlight after the...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.341517</td>\n",
              "      <td>-0.614351</td>\n",
              "      <td>0.075421</td>\n",
              "      <td>-0.381870</td>\n",
              "      <td>-0.037141</td>\n",
              "      <td>-0.639595</td>\n",
              "      <td>1.047396</td>\n",
              "      <td>1.109776</td>\n",
              "      <td>-0.500967</td>\n",
              "      <td>-0.308550</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.180812</td>\n",
              "      <td>0.402919</td>\n",
              "      <td>0.446856</td>\n",
              "      <td>-0.506134</td>\n",
              "      <td>-0.852798</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>-0.568851</td>\n",
              "      <td>-0.948410</td>\n",
              "      <td>0.342488</td>\n",
              "      <td>-0.257154</td>\n",
              "      <td>-0.041045</td>\n",
              "      <td>1.054365</td>\n",
              "      <td>0.182190</td>\n",
              "      <td>0.183331</td>\n",
              "      <td>0.685496</td>\n",
              "      <td>-0.191476</td>\n",
              "      <td>-0.196328</td>\n",
              "      <td>-0.376523</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>-0.232624</td>\n",
              "      <td>-0.124186</td>\n",
              "      <td>0.408084</td>\n",
              "      <td>0.532742</td>\n",
              "      <td>-0.697111</td>\n",
              "      <td>-0.076796</td>\n",
              "      <td>-0.269128</td>\n",
              "      <td>-0.596582</td>\n",
              "      <td>-0.246367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.507654</td>\n",
              "      <td>-0.372031</td>\n",
              "      <td>0.384393</td>\n",
              "      <td>-0.427786</td>\n",
              "      <td>-0.062957</td>\n",
              "      <td>0.381885</td>\n",
              "      <td>-0.210031</td>\n",
              "      <td>-0.373228</td>\n",
              "      <td>0.138790</td>\n",
              "      <td>-0.295719</td>\n",
              "      <td>-0.431427</td>\n",
              "      <td>-0.521123</td>\n",
              "      <td>0.406643</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>-0.539807</td>\n",
              "      <td>-0.619525</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>-0.941711</td>\n",
              "      <td>-0.363686</td>\n",
              "      <td>0.716169</td>\n",
              "      <td>-0.360151</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.696636</td>\n",
              "      <td>-0.872138</td>\n",
              "      <td>0.198449</td>\n",
              "      <td>-0.777934</td>\n",
              "      <td>0.183854</td>\n",
              "      <td>-0.967491</td>\n",
              "      <td>-0.433642</td>\n",
              "      <td>-0.074372</td>\n",
              "      <td>-0.851413</td>\n",
              "      <td>-0.311539</td>\n",
              "      <td>0.008006</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.726386</td>\n",
              "      <td>0.608123</td>\n",
              "      <td>-0.062077</td>\n",
              "      <td>exp What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 771 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1  ...  Label  Label_enc\n",
              "0 -1.280513 -0.479056  ...   DESC          1\n",
              "1  0.050765 -0.231588  ...   ENTY          2\n",
              "2  0.165783  0.086285  ...   DESC          1\n",
              "3 -0.178117 -0.473958  ...   ENTY          2\n",
              "4 -0.341517 -0.614351  ...   ABBR          0\n",
              "\n",
              "[5 rows x 771 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83kLcZswJfuy"
      },
      "source": [
        "## Derive Independent and Dependent feature from the training Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aSDp4PNt57r"
      },
      "source": [
        "features = final_train.drop(['Question','Label','Label_enc'],axis=1)\n",
        "lbls = final_train['Label_enc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "QcZciZMuvDJi",
        "outputId": "715f60a5-dfe7-470e-fb7e-823abffef9bf"
      },
      "source": [
        "features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.280513</td>\n",
              "      <td>-0.479056</td>\n",
              "      <td>-0.074593</td>\n",
              "      <td>-1.078832</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>-0.304827</td>\n",
              "      <td>0.710984</td>\n",
              "      <td>0.278826</td>\n",
              "      <td>0.129273</td>\n",
              "      <td>0.484495</td>\n",
              "      <td>0.194379</td>\n",
              "      <td>0.099252</td>\n",
              "      <td>0.048627</td>\n",
              "      <td>0.641369</td>\n",
              "      <td>0.453775</td>\n",
              "      <td>-0.550658</td>\n",
              "      <td>-0.685677</td>\n",
              "      <td>0.614255</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.382198</td>\n",
              "      <td>-0.034111</td>\n",
              "      <td>0.072872</td>\n",
              "      <td>0.070514</td>\n",
              "      <td>-0.182452</td>\n",
              "      <td>-0.672063</td>\n",
              "      <td>-0.203226</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>-0.494412</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.394312</td>\n",
              "      <td>0.036819</td>\n",
              "      <td>0.289581</td>\n",
              "      <td>0.572028</td>\n",
              "      <td>0.346302</td>\n",
              "      <td>-0.048939</td>\n",
              "      <td>0.285914</td>\n",
              "      <td>0.699641</td>\n",
              "      <td>0.078200</td>\n",
              "      <td>-0.658135</td>\n",
              "      <td>-0.720307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032483</td>\n",
              "      <td>-1.037481</td>\n",
              "      <td>-0.430439</td>\n",
              "      <td>0.345353</td>\n",
              "      <td>-0.443688</td>\n",
              "      <td>0.326153</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.017737</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.084457</td>\n",
              "      <td>-0.220593</td>\n",
              "      <td>-0.326400</td>\n",
              "      <td>0.109498</td>\n",
              "      <td>-0.313511</td>\n",
              "      <td>0.126476</td>\n",
              "      <td>-1.023944</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.276654</td>\n",
              "      <td>0.090974</td>\n",
              "      <td>-0.871338</td>\n",
              "      <td>0.066085</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.710252</td>\n",
              "      <td>0.815904</td>\n",
              "      <td>0.116723</td>\n",
              "      <td>-0.763052</td>\n",
              "      <td>-0.191135</td>\n",
              "      <td>-0.117061</td>\n",
              "      <td>-0.917495</td>\n",
              "      <td>0.238745</td>\n",
              "      <td>-0.721925</td>\n",
              "      <td>-0.708831</td>\n",
              "      <td>0.919505</td>\n",
              "      <td>0.014720</td>\n",
              "      <td>-0.218466</td>\n",
              "      <td>-0.708000</td>\n",
              "      <td>-0.060461</td>\n",
              "      <td>-0.690395</td>\n",
              "      <td>0.655526</td>\n",
              "      <td>0.429932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050765</td>\n",
              "      <td>-0.231588</td>\n",
              "      <td>0.449181</td>\n",
              "      <td>-0.434118</td>\n",
              "      <td>-0.437005</td>\n",
              "      <td>-0.025377</td>\n",
              "      <td>0.901858</td>\n",
              "      <td>0.299692</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.363240</td>\n",
              "      <td>0.813872</td>\n",
              "      <td>-0.242552</td>\n",
              "      <td>-0.046876</td>\n",
              "      <td>0.664556</td>\n",
              "      <td>0.063658</td>\n",
              "      <td>-0.778084</td>\n",
              "      <td>-0.464535</td>\n",
              "      <td>0.818348</td>\n",
              "      <td>0.217839</td>\n",
              "      <td>-0.682175</td>\n",
              "      <td>-0.048325</td>\n",
              "      <td>0.305596</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>-0.105053</td>\n",
              "      <td>-0.850086</td>\n",
              "      <td>-0.180318</td>\n",
              "      <td>0.599912</td>\n",
              "      <td>-0.693823</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>0.129673</td>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.366444</td>\n",
              "      <td>-0.351863</td>\n",
              "      <td>0.442381</td>\n",
              "      <td>0.333915</td>\n",
              "      <td>-0.367255</td>\n",
              "      <td>1.370850</td>\n",
              "      <td>-0.371236</td>\n",
              "      <td>-0.394274</td>\n",
              "      <td>0.127976</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.759870</td>\n",
              "      <td>-0.319705</td>\n",
              "      <td>-0.320549</td>\n",
              "      <td>0.269263</td>\n",
              "      <td>-0.234702</td>\n",
              "      <td>0.203369</td>\n",
              "      <td>0.363199</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.343576</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>-0.211596</td>\n",
              "      <td>0.346223</td>\n",
              "      <td>-0.544377</td>\n",
              "      <td>0.259784</td>\n",
              "      <td>-0.261309</td>\n",
              "      <td>-0.354508</td>\n",
              "      <td>-0.033133</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>0.176840</td>\n",
              "      <td>-0.155799</td>\n",
              "      <td>-1.046834</td>\n",
              "      <td>-0.140346</td>\n",
              "      <td>0.822187</td>\n",
              "      <td>1.090696</td>\n",
              "      <td>-0.127105</td>\n",
              "      <td>-1.281975</td>\n",
              "      <td>0.121476</td>\n",
              "      <td>-0.035387</td>\n",
              "      <td>-1.036540</td>\n",
              "      <td>-0.455563</td>\n",
              "      <td>-1.028529</td>\n",
              "      <td>-0.167688</td>\n",
              "      <td>-0.617333</td>\n",
              "      <td>-0.128335</td>\n",
              "      <td>-0.154140</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>-0.945878</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.169365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165783</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.996058</td>\n",
              "      <td>-0.007494</td>\n",
              "      <td>-0.062556</td>\n",
              "      <td>-0.447119</td>\n",
              "      <td>1.157737</td>\n",
              "      <td>-0.594609</td>\n",
              "      <td>-0.278916</td>\n",
              "      <td>0.288760</td>\n",
              "      <td>-0.755688</td>\n",
              "      <td>0.518913</td>\n",
              "      <td>-0.589019</td>\n",
              "      <td>-0.218036</td>\n",
              "      <td>-0.299750</td>\n",
              "      <td>-0.588890</td>\n",
              "      <td>-1.044726</td>\n",
              "      <td>0.417887</td>\n",
              "      <td>-0.516429</td>\n",
              "      <td>-0.688118</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>0.023603</td>\n",
              "      <td>-0.186256</td>\n",
              "      <td>0.847153</td>\n",
              "      <td>-0.451656</td>\n",
              "      <td>0.414896</td>\n",
              "      <td>0.153553</td>\n",
              "      <td>-0.524881</td>\n",
              "      <td>0.480987</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.525045</td>\n",
              "      <td>0.589052</td>\n",
              "      <td>-0.483123</td>\n",
              "      <td>0.143384</td>\n",
              "      <td>0.049669</td>\n",
              "      <td>-0.625911</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>-0.494312</td>\n",
              "      <td>0.039376</td>\n",
              "      <td>-0.539757</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.288382</td>\n",
              "      <td>0.158904</td>\n",
              "      <td>-0.675779</td>\n",
              "      <td>-0.603539</td>\n",
              "      <td>-0.569769</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.707026</td>\n",
              "      <td>0.829515</td>\n",
              "      <td>-0.109335</td>\n",
              "      <td>0.677547</td>\n",
              "      <td>0.197821</td>\n",
              "      <td>0.223960</td>\n",
              "      <td>-0.297395</td>\n",
              "      <td>-0.826129</td>\n",
              "      <td>-0.965579</td>\n",
              "      <td>-0.218842</td>\n",
              "      <td>1.487623</td>\n",
              "      <td>-0.247484</td>\n",
              "      <td>-0.609410</td>\n",
              "      <td>-0.065344</td>\n",
              "      <td>-0.464756</td>\n",
              "      <td>-0.134924</td>\n",
              "      <td>1.308985</td>\n",
              "      <td>0.461914</td>\n",
              "      <td>-0.319942</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.672880</td>\n",
              "      <td>0.423251</td>\n",
              "      <td>-1.299873</td>\n",
              "      <td>-0.380740</td>\n",
              "      <td>-1.354729</td>\n",
              "      <td>-0.239816</td>\n",
              "      <td>-0.171939</td>\n",
              "      <td>0.529478</td>\n",
              "      <td>-0.135893</td>\n",
              "      <td>1.097948</td>\n",
              "      <td>-0.018600</td>\n",
              "      <td>-1.401098</td>\n",
              "      <td>-0.166925</td>\n",
              "      <td>-0.666990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178117</td>\n",
              "      <td>-0.473958</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>-1.291486</td>\n",
              "      <td>-0.028840</td>\n",
              "      <td>0.348842</td>\n",
              "      <td>-0.046128</td>\n",
              "      <td>0.052367</td>\n",
              "      <td>-0.436607</td>\n",
              "      <td>1.082325</td>\n",
              "      <td>1.379477</td>\n",
              "      <td>0.269813</td>\n",
              "      <td>-0.224945</td>\n",
              "      <td>0.555075</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>-1.012060</td>\n",
              "      <td>-0.139680</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>-0.556999</td>\n",
              "      <td>-0.128182</td>\n",
              "      <td>0.313684</td>\n",
              "      <td>-0.397970</td>\n",
              "      <td>0.625162</td>\n",
              "      <td>-1.139045</td>\n",
              "      <td>0.605110</td>\n",
              "      <td>0.438818</td>\n",
              "      <td>-0.294600</td>\n",
              "      <td>-0.015436</td>\n",
              "      <td>-0.200387</td>\n",
              "      <td>-0.028176</td>\n",
              "      <td>0.543886</td>\n",
              "      <td>-0.501193</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>-0.207827</td>\n",
              "      <td>-0.185351</td>\n",
              "      <td>0.511595</td>\n",
              "      <td>-0.588324</td>\n",
              "      <td>0.523014</td>\n",
              "      <td>-0.696837</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.323599</td>\n",
              "      <td>-0.134632</td>\n",
              "      <td>-0.420600</td>\n",
              "      <td>-0.185516</td>\n",
              "      <td>-0.183404</td>\n",
              "      <td>0.793519</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.518475</td>\n",
              "      <td>0.655392</td>\n",
              "      <td>0.389528</td>\n",
              "      <td>-0.159402</td>\n",
              "      <td>0.155687</td>\n",
              "      <td>-0.318773</td>\n",
              "      <td>-0.182897</td>\n",
              "      <td>-0.584351</td>\n",
              "      <td>-1.437036</td>\n",
              "      <td>0.627801</td>\n",
              "      <td>0.532542</td>\n",
              "      <td>0.662939</td>\n",
              "      <td>0.678888</td>\n",
              "      <td>-0.622288</td>\n",
              "      <td>0.319153</td>\n",
              "      <td>0.996853</td>\n",
              "      <td>0.696456</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>-0.387256</td>\n",
              "      <td>0.541325</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>-0.789448</td>\n",
              "      <td>-0.599024</td>\n",
              "      <td>-0.941752</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>-0.710274</td>\n",
              "      <td>0.030269</td>\n",
              "      <td>0.281970</td>\n",
              "      <td>0.180029</td>\n",
              "      <td>0.274251</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>1.007164</td>\n",
              "      <td>-0.209413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.341517</td>\n",
              "      <td>-0.614351</td>\n",
              "      <td>0.075421</td>\n",
              "      <td>-0.381870</td>\n",
              "      <td>-0.037141</td>\n",
              "      <td>-0.639595</td>\n",
              "      <td>1.047396</td>\n",
              "      <td>1.109776</td>\n",
              "      <td>-0.500967</td>\n",
              "      <td>-0.308550</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.180812</td>\n",
              "      <td>0.402919</td>\n",
              "      <td>0.446856</td>\n",
              "      <td>-0.506134</td>\n",
              "      <td>-0.852798</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>-0.568851</td>\n",
              "      <td>-0.948410</td>\n",
              "      <td>0.342488</td>\n",
              "      <td>-0.257154</td>\n",
              "      <td>-0.041045</td>\n",
              "      <td>1.054365</td>\n",
              "      <td>0.182190</td>\n",
              "      <td>0.183331</td>\n",
              "      <td>0.685496</td>\n",
              "      <td>-0.191476</td>\n",
              "      <td>-0.196328</td>\n",
              "      <td>-0.376523</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>-0.232624</td>\n",
              "      <td>-0.124186</td>\n",
              "      <td>0.408084</td>\n",
              "      <td>0.532742</td>\n",
              "      <td>-0.697111</td>\n",
              "      <td>-0.076796</td>\n",
              "      <td>-0.269128</td>\n",
              "      <td>-0.596582</td>\n",
              "      <td>-0.246367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.935546</td>\n",
              "      <td>0.314507</td>\n",
              "      <td>-0.171532</td>\n",
              "      <td>-0.507654</td>\n",
              "      <td>-0.372031</td>\n",
              "      <td>0.384393</td>\n",
              "      <td>-0.427786</td>\n",
              "      <td>-0.062957</td>\n",
              "      <td>0.381885</td>\n",
              "      <td>-0.210031</td>\n",
              "      <td>-0.373228</td>\n",
              "      <td>0.138790</td>\n",
              "      <td>-0.295719</td>\n",
              "      <td>-0.431427</td>\n",
              "      <td>-0.521123</td>\n",
              "      <td>0.406643</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>-0.539807</td>\n",
              "      <td>-0.619525</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>-0.941711</td>\n",
              "      <td>-0.363686</td>\n",
              "      <td>0.716169</td>\n",
              "      <td>-0.360151</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.696636</td>\n",
              "      <td>-0.872138</td>\n",
              "      <td>0.198449</td>\n",
              "      <td>-0.777934</td>\n",
              "      <td>0.183854</td>\n",
              "      <td>-0.967491</td>\n",
              "      <td>-0.433642</td>\n",
              "      <td>-0.074372</td>\n",
              "      <td>-0.851413</td>\n",
              "      <td>-0.311539</td>\n",
              "      <td>0.008006</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.726386</td>\n",
              "      <td>0.608123</td>\n",
              "      <td>-0.062077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       765       766       767\n",
              "0 -1.280513 -0.479056 -0.074593  ... -0.690395  0.655526  0.429932\n",
              "1  0.050765 -0.231588  0.449181  ... -0.945878  0.582182  0.169365\n",
              "2  0.165783  0.086285  0.996058  ... -1.401098 -0.166925 -0.666990\n",
              "3 -0.178117 -0.473958  0.048356  ... -0.035899  1.007164 -0.209413\n",
              "4 -0.341517 -0.614351  0.075421  ... -0.726386  0.608123 -0.062077\n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buZO56pFJn4a"
      },
      "source": [
        "## Split the training sample into Training and validation Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53p39zFZvNkb"
      },
      "source": [
        "X_train,X_val,Y_train,Y_val = train_test_split(features,lbls,test_size=0.15,stratify=lbls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic1alSpxxckV",
        "outputId": "e8835a10-074e-4536-8023-a6ee35ed7913"
      },
      "source": [
        "X_train.shape,X_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4634, 768), (818, 768))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpvudX_XJvtq"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9d8QrAfwEro"
      },
      "source": [
        "## Build Model - LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0TJ1HBmw0eh",
        "outputId": "dd4d1568-7b25-4095-d8f8-ff5e20ef04e3"
      },
      "source": [
        "lr = LogisticRegression(multi_class='ovr')\n",
        "lr.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th-XiRUnyIEh"
      },
      "source": [
        "## Validation  Predictions accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgsKpqz-yKF7",
        "outputId": "4549caa9-41e2-41c6-9547-db473cb36df4"
      },
      "source": [
        "y_pred = lr.predict(X_val)\n",
        "accuracy_score(y_pred,Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8899755501222494"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SIDL3CRx_ox"
      },
      "source": [
        "## Applying Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vl8bn-_yB48"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhPANue2_cA"
      },
      "source": [
        "temp = features\n",
        "target = lbls\n",
        "scores = []\n",
        "scores_val = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kh6nLKou1XEB",
        "outputId": "99147bcb-73a9-4545-b777-38fb968dbf8c"
      },
      "source": [
        "for train_index,test_index in skf.split(temp,target):\n",
        "        xtrain,xtest = temp[temp.index.isin(train_index)],temp[temp.index.isin(test_index)]\n",
        "        ytrain,ytest = target[train_index],target[test_index]\n",
        "        \n",
        "        model  = LogisticRegression(multi_class='ovr')\n",
        "\n",
        "        model.fit(xtrain,ytrain)\n",
        "            \n",
        "        preds = model.predict(xtest)\n",
        "        \n",
        "        print(accuracy_score(ytest,preds))\n",
        "        scores.append(accuracy_score(ytest,preds))\n",
        "        #\n",
        "#\n",
        "#        \n",
        "print('-----------KFOLD--------------')\n",
        "print(sns.lineplot(x=[i for i in range(len(scores))],y=scores))\n",
        "print(min(scores),max(scores),np.mean(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8817598533455545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8918423464711274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8788990825688073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8752293577981651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8926605504587156\n",
            "-----------KFOLD--------------\n",
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "0.8752293577981651 0.8926605504587156 0.884078238128474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK19eFPd5nkt"
      },
      "source": [
        "## Make Predictions on validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "e2VPRya4C9nc",
        "outputId": "3d5e85bf-be25-4a44-ef08-e36ed1c83574"
      },
      "source": [
        "final_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.280513</td>\n",
              "      <td>-0.479056</td>\n",
              "      <td>-0.074593</td>\n",
              "      <td>-1.078832</td>\n",
              "      <td>0.555026</td>\n",
              "      <td>-0.304827</td>\n",
              "      <td>0.710984</td>\n",
              "      <td>0.278826</td>\n",
              "      <td>0.129273</td>\n",
              "      <td>0.484495</td>\n",
              "      <td>0.194379</td>\n",
              "      <td>0.099252</td>\n",
              "      <td>0.048627</td>\n",
              "      <td>0.641369</td>\n",
              "      <td>0.453775</td>\n",
              "      <td>-0.550658</td>\n",
              "      <td>-0.685677</td>\n",
              "      <td>0.614255</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.382198</td>\n",
              "      <td>-0.034111</td>\n",
              "      <td>0.072872</td>\n",
              "      <td>0.070514</td>\n",
              "      <td>-0.182452</td>\n",
              "      <td>-0.672063</td>\n",
              "      <td>-0.203226</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>-0.494412</td>\n",
              "      <td>-0.015926</td>\n",
              "      <td>0.394312</td>\n",
              "      <td>0.036819</td>\n",
              "      <td>0.289581</td>\n",
              "      <td>0.572028</td>\n",
              "      <td>0.346302</td>\n",
              "      <td>-0.048939</td>\n",
              "      <td>0.285914</td>\n",
              "      <td>0.699641</td>\n",
              "      <td>0.078200</td>\n",
              "      <td>-0.658135</td>\n",
              "      <td>-0.720307</td>\n",
              "      <td>...</td>\n",
              "      <td>0.345353</td>\n",
              "      <td>-0.443688</td>\n",
              "      <td>0.326153</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.017737</td>\n",
              "      <td>0.361109</td>\n",
              "      <td>0.084457</td>\n",
              "      <td>-0.220593</td>\n",
              "      <td>-0.326400</td>\n",
              "      <td>0.109498</td>\n",
              "      <td>-0.313511</td>\n",
              "      <td>0.126476</td>\n",
              "      <td>-1.023944</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.276654</td>\n",
              "      <td>0.090974</td>\n",
              "      <td>-0.871338</td>\n",
              "      <td>0.066085</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.710252</td>\n",
              "      <td>0.815904</td>\n",
              "      <td>0.116723</td>\n",
              "      <td>-0.763052</td>\n",
              "      <td>-0.191135</td>\n",
              "      <td>-0.117061</td>\n",
              "      <td>-0.917495</td>\n",
              "      <td>0.238745</td>\n",
              "      <td>-0.721925</td>\n",
              "      <td>-0.708831</td>\n",
              "      <td>0.919505</td>\n",
              "      <td>0.014720</td>\n",
              "      <td>-0.218466</td>\n",
              "      <td>-0.708000</td>\n",
              "      <td>-0.060461</td>\n",
              "      <td>-0.690395</td>\n",
              "      <td>0.655526</td>\n",
              "      <td>0.429932</td>\n",
              "      <td>manner How did serfdom develop in and then lea...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.050765</td>\n",
              "      <td>-0.231588</td>\n",
              "      <td>0.449181</td>\n",
              "      <td>-0.434118</td>\n",
              "      <td>-0.437005</td>\n",
              "      <td>-0.025377</td>\n",
              "      <td>0.901858</td>\n",
              "      <td>0.299692</td>\n",
              "      <td>0.397571</td>\n",
              "      <td>0.363240</td>\n",
              "      <td>0.813872</td>\n",
              "      <td>-0.242552</td>\n",
              "      <td>-0.046876</td>\n",
              "      <td>0.664556</td>\n",
              "      <td>0.063658</td>\n",
              "      <td>-0.778084</td>\n",
              "      <td>-0.464535</td>\n",
              "      <td>0.818348</td>\n",
              "      <td>0.217839</td>\n",
              "      <td>-0.682175</td>\n",
              "      <td>-0.048325</td>\n",
              "      <td>0.305596</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>-0.105053</td>\n",
              "      <td>-0.850086</td>\n",
              "      <td>-0.180318</td>\n",
              "      <td>0.599912</td>\n",
              "      <td>-0.693823</td>\n",
              "      <td>-0.018519</td>\n",
              "      <td>0.129673</td>\n",
              "      <td>0.459312</td>\n",
              "      <td>0.366444</td>\n",
              "      <td>-0.351863</td>\n",
              "      <td>0.442381</td>\n",
              "      <td>0.333915</td>\n",
              "      <td>-0.367255</td>\n",
              "      <td>1.370850</td>\n",
              "      <td>-0.371236</td>\n",
              "      <td>-0.394274</td>\n",
              "      <td>0.127976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.269263</td>\n",
              "      <td>-0.234702</td>\n",
              "      <td>0.203369</td>\n",
              "      <td>0.363199</td>\n",
              "      <td>0.800868</td>\n",
              "      <td>0.343576</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>-0.211596</td>\n",
              "      <td>0.346223</td>\n",
              "      <td>-0.544377</td>\n",
              "      <td>0.259784</td>\n",
              "      <td>-0.261309</td>\n",
              "      <td>-0.354508</td>\n",
              "      <td>-0.033133</td>\n",
              "      <td>0.439806</td>\n",
              "      <td>0.176840</td>\n",
              "      <td>-0.155799</td>\n",
              "      <td>-1.046834</td>\n",
              "      <td>-0.140346</td>\n",
              "      <td>0.822187</td>\n",
              "      <td>1.090696</td>\n",
              "      <td>-0.127105</td>\n",
              "      <td>-1.281975</td>\n",
              "      <td>0.121476</td>\n",
              "      <td>-0.035387</td>\n",
              "      <td>-1.036540</td>\n",
              "      <td>-0.455563</td>\n",
              "      <td>-1.028529</td>\n",
              "      <td>-0.167688</td>\n",
              "      <td>-0.617333</td>\n",
              "      <td>-0.128335</td>\n",
              "      <td>-0.154140</td>\n",
              "      <td>0.052782</td>\n",
              "      <td>0.287510</td>\n",
              "      <td>-0.945878</td>\n",
              "      <td>0.582182</td>\n",
              "      <td>0.169365</td>\n",
              "      <td>cremat What films featured the character Popey...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165783</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.996058</td>\n",
              "      <td>-0.007494</td>\n",
              "      <td>-0.062556</td>\n",
              "      <td>-0.447119</td>\n",
              "      <td>1.157737</td>\n",
              "      <td>-0.594609</td>\n",
              "      <td>-0.278916</td>\n",
              "      <td>0.288760</td>\n",
              "      <td>-0.755688</td>\n",
              "      <td>0.518913</td>\n",
              "      <td>-0.589019</td>\n",
              "      <td>-0.218036</td>\n",
              "      <td>-0.299750</td>\n",
              "      <td>-0.588890</td>\n",
              "      <td>-1.044726</td>\n",
              "      <td>0.417887</td>\n",
              "      <td>-0.516429</td>\n",
              "      <td>-0.688118</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>0.023603</td>\n",
              "      <td>-0.186256</td>\n",
              "      <td>0.847153</td>\n",
              "      <td>-0.451656</td>\n",
              "      <td>0.414896</td>\n",
              "      <td>0.153553</td>\n",
              "      <td>-0.524881</td>\n",
              "      <td>0.480987</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.525045</td>\n",
              "      <td>0.589052</td>\n",
              "      <td>-0.483123</td>\n",
              "      <td>0.143384</td>\n",
              "      <td>0.049669</td>\n",
              "      <td>-0.625911</td>\n",
              "      <td>1.300623</td>\n",
              "      <td>-0.494312</td>\n",
              "      <td>0.039376</td>\n",
              "      <td>-0.539757</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.603539</td>\n",
              "      <td>-0.569769</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.707026</td>\n",
              "      <td>0.829515</td>\n",
              "      <td>-0.109335</td>\n",
              "      <td>0.677547</td>\n",
              "      <td>0.197821</td>\n",
              "      <td>0.223960</td>\n",
              "      <td>-0.297395</td>\n",
              "      <td>-0.826129</td>\n",
              "      <td>-0.965579</td>\n",
              "      <td>-0.218842</td>\n",
              "      <td>1.487623</td>\n",
              "      <td>-0.247484</td>\n",
              "      <td>-0.609410</td>\n",
              "      <td>-0.065344</td>\n",
              "      <td>-0.464756</td>\n",
              "      <td>-0.134924</td>\n",
              "      <td>1.308985</td>\n",
              "      <td>0.461914</td>\n",
              "      <td>-0.319942</td>\n",
              "      <td>-0.315665</td>\n",
              "      <td>-0.672880</td>\n",
              "      <td>0.423251</td>\n",
              "      <td>-1.299873</td>\n",
              "      <td>-0.380740</td>\n",
              "      <td>-1.354729</td>\n",
              "      <td>-0.239816</td>\n",
              "      <td>-0.171939</td>\n",
              "      <td>0.529478</td>\n",
              "      <td>-0.135893</td>\n",
              "      <td>1.097948</td>\n",
              "      <td>-0.018600</td>\n",
              "      <td>-1.401098</td>\n",
              "      <td>-0.166925</td>\n",
              "      <td>-0.666990</td>\n",
              "      <td>manner How can I find a list of celebrities ' ...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.178117</td>\n",
              "      <td>-0.473958</td>\n",
              "      <td>0.048356</td>\n",
              "      <td>-1.291486</td>\n",
              "      <td>-0.028840</td>\n",
              "      <td>0.348842</td>\n",
              "      <td>-0.046128</td>\n",
              "      <td>0.052367</td>\n",
              "      <td>-0.436607</td>\n",
              "      <td>1.082325</td>\n",
              "      <td>1.379477</td>\n",
              "      <td>0.269813</td>\n",
              "      <td>-0.224945</td>\n",
              "      <td>0.555075</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>-1.012060</td>\n",
              "      <td>-0.139680</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>-0.556999</td>\n",
              "      <td>-0.128182</td>\n",
              "      <td>0.313684</td>\n",
              "      <td>-0.397970</td>\n",
              "      <td>0.625162</td>\n",
              "      <td>-1.139045</td>\n",
              "      <td>0.605110</td>\n",
              "      <td>0.438818</td>\n",
              "      <td>-0.294600</td>\n",
              "      <td>-0.015436</td>\n",
              "      <td>-0.200387</td>\n",
              "      <td>-0.028176</td>\n",
              "      <td>0.543886</td>\n",
              "      <td>-0.501193</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>-0.207827</td>\n",
              "      <td>-0.185351</td>\n",
              "      <td>0.511595</td>\n",
              "      <td>-0.588324</td>\n",
              "      <td>0.523014</td>\n",
              "      <td>-0.696837</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.185516</td>\n",
              "      <td>-0.183404</td>\n",
              "      <td>0.793519</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.518475</td>\n",
              "      <td>0.655392</td>\n",
              "      <td>0.389528</td>\n",
              "      <td>-0.159402</td>\n",
              "      <td>0.155687</td>\n",
              "      <td>-0.318773</td>\n",
              "      <td>-0.182897</td>\n",
              "      <td>-0.584351</td>\n",
              "      <td>-1.437036</td>\n",
              "      <td>0.627801</td>\n",
              "      <td>0.532542</td>\n",
              "      <td>0.662939</td>\n",
              "      <td>0.678888</td>\n",
              "      <td>-0.622288</td>\n",
              "      <td>0.319153</td>\n",
              "      <td>0.996853</td>\n",
              "      <td>0.696456</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>-0.387256</td>\n",
              "      <td>0.541325</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>-0.789448</td>\n",
              "      <td>-0.599024</td>\n",
              "      <td>-0.941752</td>\n",
              "      <td>0.158490</td>\n",
              "      <td>-0.710274</td>\n",
              "      <td>0.030269</td>\n",
              "      <td>0.281970</td>\n",
              "      <td>0.180029</td>\n",
              "      <td>0.274251</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>1.007164</td>\n",
              "      <td>-0.209413</td>\n",
              "      <td>animal What fowl grabs the spotlight after the...</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.341517</td>\n",
              "      <td>-0.614351</td>\n",
              "      <td>0.075421</td>\n",
              "      <td>-0.381870</td>\n",
              "      <td>-0.037141</td>\n",
              "      <td>-0.639595</td>\n",
              "      <td>1.047396</td>\n",
              "      <td>1.109776</td>\n",
              "      <td>-0.500967</td>\n",
              "      <td>-0.308550</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.180812</td>\n",
              "      <td>0.402919</td>\n",
              "      <td>0.446856</td>\n",
              "      <td>-0.506134</td>\n",
              "      <td>-0.852798</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>-0.568851</td>\n",
              "      <td>-0.948410</td>\n",
              "      <td>0.342488</td>\n",
              "      <td>-0.257154</td>\n",
              "      <td>-0.041045</td>\n",
              "      <td>1.054365</td>\n",
              "      <td>0.182190</td>\n",
              "      <td>0.183331</td>\n",
              "      <td>0.685496</td>\n",
              "      <td>-0.191476</td>\n",
              "      <td>-0.196328</td>\n",
              "      <td>-0.376523</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>-0.232624</td>\n",
              "      <td>-0.124186</td>\n",
              "      <td>0.408084</td>\n",
              "      <td>0.532742</td>\n",
              "      <td>-0.697111</td>\n",
              "      <td>-0.076796</td>\n",
              "      <td>-0.269128</td>\n",
              "      <td>-0.596582</td>\n",
              "      <td>-0.246367</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.507654</td>\n",
              "      <td>-0.372031</td>\n",
              "      <td>0.384393</td>\n",
              "      <td>-0.427786</td>\n",
              "      <td>-0.062957</td>\n",
              "      <td>0.381885</td>\n",
              "      <td>-0.210031</td>\n",
              "      <td>-0.373228</td>\n",
              "      <td>0.138790</td>\n",
              "      <td>-0.295719</td>\n",
              "      <td>-0.431427</td>\n",
              "      <td>-0.521123</td>\n",
              "      <td>0.406643</td>\n",
              "      <td>0.222614</td>\n",
              "      <td>-0.539807</td>\n",
              "      <td>-0.619525</td>\n",
              "      <td>0.157020</td>\n",
              "      <td>-0.941711</td>\n",
              "      <td>-0.363686</td>\n",
              "      <td>0.716169</td>\n",
              "      <td>-0.360151</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.696636</td>\n",
              "      <td>-0.872138</td>\n",
              "      <td>0.198449</td>\n",
              "      <td>-0.777934</td>\n",
              "      <td>0.183854</td>\n",
              "      <td>-0.967491</td>\n",
              "      <td>-0.433642</td>\n",
              "      <td>-0.074372</td>\n",
              "      <td>-0.851413</td>\n",
              "      <td>-0.311539</td>\n",
              "      <td>0.008006</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.726386</td>\n",
              "      <td>0.608123</td>\n",
              "      <td>-0.062077</td>\n",
              "      <td>exp What is the full form of .com ?\\n</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 771 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1  ...  Label  Label_enc\n",
              "0 -1.280513 -0.479056  ...   DESC          1\n",
              "1  0.050765 -0.231588  ...   ENTY          2\n",
              "2  0.165783  0.086285  ...   DESC          1\n",
              "3 -0.178117 -0.473958  ...   ENTY          2\n",
              "4 -0.341517 -0.614351  ...   ABBR          0\n",
              "\n",
              "[5 rows x 771 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WogvLgZKTie"
      },
      "source": [
        "## Doing the split again to asociate the questions and corresponding labels with the training and validation sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEj_USyCDgp1"
      },
      "source": [
        "X_train,X_val,Y_train,Y_val = train_test_split(final_train.drop('Label_enc',axis=1),final_train['Label_enc'],test_size=0.15,stratify=final_train['Label_enc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXHoj6p4D9k1"
      },
      "source": [
        "X_val_new = X_val.drop(['Question','Label'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZfHPfn4ftI"
      },
      "source": [
        "y_pred = model.predict(X_val_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIab43rWCqlR",
        "outputId": "a4fed110-ced1-4055-d19e-60576dd33af6"
      },
      "source": [
        "len(y_pred )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_nXKu0NKdkW"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByrFPen4Kih_"
      },
      "source": [
        "#### Label Mapping\n",
        "**{0: 'ABBR', 1: 'DESC', 2: 'ENTY', 3: 'HUM', 4: 'LOC', 5: 'NUM'}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FVRmUZaf4ZdQ",
        "outputId": "1021153b-4e06-4ff4-c75f-cdd92a652f4e"
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_pred,Y_val),annot=True,fmt=\".2f\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3517d11210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbkFMr-jKosJ"
      },
      "source": [
        "## Retrieve Prediction Probabilities for Each Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbb2ew0x7D-c"
      },
      "source": [
        "pred_proba = model.predict_proba(X_val_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIaZ3eH28BKe",
        "outputId": "f2ee2cb3-08cf-49ac-88e8-285de0ddbff1"
      },
      "source": [
        "pred_proba "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.67967062e-05, 1.37483021e-04, 2.91446292e-02, 9.69867262e-01,\n",
              "        7.78579392e-04, 5.52492925e-05],\n",
              "       [2.63708398e-04, 9.54780874e-01, 3.13930487e-02, 1.30276628e-02,\n",
              "        8.78448417e-07, 5.33827550e-04],\n",
              "       [3.84414741e-04, 9.79077547e-01, 1.11563144e-03, 1.43318551e-04,\n",
              "        3.21376154e-05, 1.92469510e-02],\n",
              "       ...,\n",
              "       [1.19282102e-06, 2.70288272e-02, 9.67846654e-01, 4.59445779e-03,\n",
              "        3.72649310e-04, 1.56219290e-04],\n",
              "       [2.00835630e-03, 2.65582968e-01, 6.40111163e-04, 7.31531580e-01,\n",
              "        2.36023718e-04, 9.60893969e-07],\n",
              "       [1.53236552e-04, 3.04565392e-01, 6.95252435e-01, 5.90478023e-07,\n",
              "        2.79649340e-05, 3.81095755e-07]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gPftnH9KvaJ"
      },
      "source": [
        "## Store the prediction Probabilities into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zwRcmiB8F8s"
      },
      "source": [
        "df_pred = pd.DataFrame(pred_proba,columns=lb.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "60tg3pMY8ywf",
        "outputId": "2dc24d52-42af-460b-88b0-17470e5dcabd"
      },
      "source": [
        "df_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABBR</th>\n",
              "      <th>DESC</th>\n",
              "      <th>ENTY</th>\n",
              "      <th>HUM</th>\n",
              "      <th>LOC</th>\n",
              "      <th>NUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.029145</td>\n",
              "      <td>9.698673e-01</td>\n",
              "      <td>7.785794e-04</td>\n",
              "      <td>5.524929e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.954781</td>\n",
              "      <td>0.031393</td>\n",
              "      <td>1.302766e-02</td>\n",
              "      <td>8.784484e-07</td>\n",
              "      <td>5.338276e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.979078</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>1.433186e-04</td>\n",
              "      <td>3.213762e-05</td>\n",
              "      <td>1.924695e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.050993</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>1.272275e-04</td>\n",
              "      <td>7.109687e-03</td>\n",
              "      <td>9.413756e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>3.754166e-04</td>\n",
              "      <td>3.048897e-05</td>\n",
              "      <td>9.317863e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000865</td>\n",
              "      <td>0.966235</td>\n",
              "      <td>9.330449e-07</td>\n",
              "      <td>4.361736e-04</td>\n",
              "      <td>3.223346e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.843561</td>\n",
              "      <td>0.155315</td>\n",
              "      <td>4.833663e-04</td>\n",
              "      <td>2.483263e-05</td>\n",
              "      <td>5.369831e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.027029</td>\n",
              "      <td>0.967847</td>\n",
              "      <td>4.594458e-03</td>\n",
              "      <td>3.726493e-04</td>\n",
              "      <td>1.562193e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.265583</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>7.315316e-01</td>\n",
              "      <td>2.360237e-04</td>\n",
              "      <td>9.608940e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>0.000153</td>\n",
              "      <td>0.304565</td>\n",
              "      <td>0.695252</td>\n",
              "      <td>5.904780e-07</td>\n",
              "      <td>2.796493e-05</td>\n",
              "      <td>3.810958e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>818 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ABBR      DESC      ENTY           HUM           LOC           NUM\n",
              "0    0.000017  0.000137  0.029145  9.698673e-01  7.785794e-04  5.524929e-05\n",
              "1    0.000264  0.954781  0.031393  1.302766e-02  8.784484e-07  5.338276e-04\n",
              "2    0.000384  0.979078  0.001116  1.433186e-04  3.213762e-05  1.924695e-02\n",
              "3    0.000365  0.050993  0.000029  1.272275e-04  7.109687e-03  9.413756e-01\n",
              "4    0.000002  0.067660  0.000145  3.754166e-04  3.048897e-05  9.317863e-01\n",
              "..        ...       ...       ...           ...           ...           ...\n",
              "813  0.000229  0.000865  0.966235  9.330449e-07  4.361736e-04  3.223346e-02\n",
              "814  0.000562  0.843561  0.155315  4.833663e-04  2.483263e-05  5.369831e-05\n",
              "815  0.000001  0.027029  0.967847  4.594458e-03  3.726493e-04  1.562193e-04\n",
              "816  0.002008  0.265583  0.000640  7.315316e-01  2.360237e-04  9.608940e-07\n",
              "817  0.000153  0.304565  0.695252  5.904780e-07  2.796493e-05  3.810958e-07\n",
              "\n",
              "[818 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYHdaXW4K1-n"
      },
      "source": [
        "## Formatting the Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "4AITNCgAFH5f",
        "outputId": "32e72100-b116-4ebf-a242-846914362b67"
      },
      "source": [
        "X_val[['Question','Label']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>ind Who killed Martin Luther King ?\\n</td>\n",
              "      <td>HUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5127</th>\n",
              "      <td>def What is fellatio ?\\n</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4449</th>\n",
              "      <td>manner How do they get Teflon to stick to the ...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4439</th>\n",
              "      <td>dist How tall is the Matterhorn ?\\n</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1706</th>\n",
              "      <td>count How many people were executed for Abraha...</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>sport In what sport are these following number...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3171</th>\n",
              "      <td>desc What happens to used motor oil ?\\n</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2538</th>\n",
              "      <td>color What is your favorite color ?\\n</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2076</th>\n",
              "      <td>gr What court does Bob Woodward describe in Th...</td>\n",
              "      <td>HUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2089</th>\n",
              "      <td>reason Why do some people have two different c...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>818 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Question Label\n",
              "4197              ind Who killed Martin Luther King ?\\n   HUM\n",
              "5127                           def What is fellatio ?\\n  DESC\n",
              "4449  manner How do they get Teflon to stick to the ...  DESC\n",
              "4439                dist How tall is the Matterhorn ?\\n   NUM\n",
              "1706  count How many people were executed for Abraha...   NUM\n",
              "...                                                 ...   ...\n",
              "694   sport In what sport are these following number...  ENTY\n",
              "3171            desc What happens to used motor oil ?\\n  DESC\n",
              "2538              color What is your favorite color ?\\n  ENTY\n",
              "2076  gr What court does Bob Woodward describe in Th...   HUM\n",
              "2089  reason Why do some people have two different c...  DESC\n",
              "\n",
              "[818 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JPP5q_EB2Te"
      },
      "source": [
        "predictions_made = X_val[['Question','Label']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcuMqg9DCxs-"
      },
      "source": [
        "predictions_made['Label_Predicted'] = y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "hH388mSTFPK1",
        "outputId": "5ad6b067-04b5-4c5d-9811-48c425fafca2"
      },
      "source": [
        "predictions_made.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label_Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>ind Who killed Martin Luther King ?\\n</td>\n",
              "      <td>HUM</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5127</th>\n",
              "      <td>def What is fellatio ?\\n</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4449</th>\n",
              "      <td>manner How do they get Teflon to stick to the ...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4439</th>\n",
              "      <td>dist How tall is the Matterhorn ?\\n</td>\n",
              "      <td>NUM</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1706</th>\n",
              "      <td>count How many people were executed for Abraha...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Question Label  Label_Predicted\n",
              "4197              ind Who killed Martin Luther King ?\\n   HUM                3\n",
              "5127                           def What is fellatio ?\\n  DESC                1\n",
              "4449  manner How do they get Teflon to stick to the ...  DESC                1\n",
              "4439                dist How tall is the Matterhorn ?\\n   NUM                5\n",
              "1706  count How many people were executed for Abraha...   NUM                5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onMWQopfF6XM",
        "outputId": "8ce9131a-ce5f-4a77-d9dc-e9d72da7f58e"
      },
      "source": [
        "predictions_made['Label_Predicted'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 5, 2, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQuvn54mK6mQ"
      },
      "source": [
        "## Generate Label Mapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlbuqgzEFYxE",
        "outputId": "e936b380-5781-43fc-c678-7f7869fa497d"
      },
      "source": [
        "mapper = {k:v for k,v in enumerate(lb.classes_.tolist())}\n",
        "mapper "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ABBR', 1: 'DESC', 2: 'ENTY', 3: 'HUM', 4: 'LOC', 5: 'NUM'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSTV8jGFVeY"
      },
      "source": [
        "predictions_made['Label_Predicted'] = predictions_made['Label_Predicted'].map(mapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZOzHmOyFxkX"
      },
      "source": [
        "predictions_made.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "R57cLZigIgbC",
        "outputId": "48874211-0fff-42bb-aa11-50462198d96f"
      },
      "source": [
        "predictions_made = predictions_made.drop('index',axis=1)\n",
        "predictions_made.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label_Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind Who killed Martin Luther King ?\\n</td>\n",
              "      <td>HUM</td>\n",
              "      <td>HUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>def What is fellatio ?\\n</td>\n",
              "      <td>DESC</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>manner How do they get Teflon to stick to the ...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dist How tall is the Matterhorn ?\\n</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>count How many people were executed for Abraha...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question Label Label_Predicted\n",
              "0              ind Who killed Martin Luther King ?\\n   HUM             HUM\n",
              "1                           def What is fellatio ?\\n  DESC            DESC\n",
              "2  manner How do they get Teflon to stick to the ...  DESC            DESC\n",
              "3                dist How tall is the Matterhorn ?\\n   NUM             NUM\n",
              "4  count How many people were executed for Abraha...   NUM             NUM"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo7UL5lPCeZG"
      },
      "source": [
        "final_validation_preds = pd.concat((predictions_made,df_pred),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "WQf7UlrfE3lr",
        "outputId": "63d988bb-3b27-4e46-aa0c-4bfc66b83f74"
      },
      "source": [
        "final_validation_preds.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label_Predicted</th>\n",
              "      <th>ABBR</th>\n",
              "      <th>DESC</th>\n",
              "      <th>ENTY</th>\n",
              "      <th>HUM</th>\n",
              "      <th>LOC</th>\n",
              "      <th>NUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind Who killed Martin Luther King ?\\n</td>\n",
              "      <td>HUM</td>\n",
              "      <td>HUM</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.029145</td>\n",
              "      <td>0.969867</td>\n",
              "      <td>7.785794e-04</td>\n",
              "      <td>0.000055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>def What is fellatio ?\\n</td>\n",
              "      <td>DESC</td>\n",
              "      <td>DESC</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.954781</td>\n",
              "      <td>0.031393</td>\n",
              "      <td>0.013028</td>\n",
              "      <td>8.784484e-07</td>\n",
              "      <td>0.000534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>manner How do they get Teflon to stick to the ...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>DESC</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.979078</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>3.213762e-05</td>\n",
              "      <td>0.019247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dist How tall is the Matterhorn ?\\n</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.050993</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>7.109687e-03</td>\n",
              "      <td>0.941376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>count How many people were executed for Abraha...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.067660</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>3.048897e-05</td>\n",
              "      <td>0.931786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ...       NUM\n",
              "0              ind Who killed Martin Luther King ?\\n  ...  0.000055\n",
              "1                           def What is fellatio ?\\n  ...  0.000534\n",
              "2  manner How do they get Teflon to stick to the ...  ...  0.019247\n",
              "3                dist How tall is the Matterhorn ?\\n  ...  0.941376\n",
              "4  count How many people were executed for Abraha...  ...  0.931786\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etdDxoEM5wcg"
      },
      "source": [
        "##Make Predictions on unseen data sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjymdGeozf5Q"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeyR-ul63kWt",
        "outputId": "ca627daa-99a4-4ebc-f17e-9782fd237967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "TEST.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No.</th>\n",
              "      <th>Question</th>\n",
              "      <th>Actual Label</th>\n",
              "      <th>Predicted Label</th>\n",
              "      <th>ABBR</th>\n",
              "      <th>DESC</th>\n",
              "      <th>ENTY</th>\n",
              "      <th>HUM</th>\n",
              "      <th>LOC</th>\n",
              "      <th>NUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Who is Genpact's CEO ?</td>\n",
              "      <td>HUM</td>\n",
              "      <td>HUM</td>\n",
              "      <td>2.144840e-03</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.996844</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What was the diluted earnings per share for Ge...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NUM</td>\n",
              "      <td>3.358860e-07</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.208753</td>\n",
              "      <td>0.090547</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.700545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>What was the final verdict in Pralipsa Rout vs...</td>\n",
              "      <td>DESC</td>\n",
              "      <td>DESC</td>\n",
              "      <td>3.685663e-04</td>\n",
              "      <td>0.829172</td>\n",
              "      <td>0.035295</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.134433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What is the court’s’ notice number that allows...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>3.143958e-05</td>\n",
              "      <td>0.150287</td>\n",
              "      <td>0.836988</td>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.008959</td>\n",
              "      <td>0.002809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>What are the components in the monthly gross s...</td>\n",
              "      <td>DESC/ENTY</td>\n",
              "      <td>NUM</td>\n",
              "      <td>1.023865e-06</td>\n",
              "      <td>0.005718</td>\n",
              "      <td>0.004760</td>\n",
              "      <td>0.000311</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.989185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   S.No.                                           Question  ...       LOC       NUM\n",
              "0      1                             Who is Genpact's CEO ?  ...  0.000040  0.000231\n",
              "1      2  What was the diluted earnings per share for Ge...  ...  0.000074  0.700545\n",
              "2      3  What was the final verdict in Pralipsa Rout vs...  ...  0.000011  0.134433\n",
              "3      4  What is the court’s’ notice number that allows...  ...  0.008959  0.002809\n",
              "4      5  What are the components in the monthly gross s...  ...  0.000025  0.989185\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y83H9hEi7Anp"
      },
      "source": [
        "class process_test_data():\n",
        "  def __init__(self,file_path,model_path):\n",
        "    self.file_path = file_path\n",
        "    self.model_path = model_path\n",
        "  def read_data(self):\n",
        "    TEST = pd.read_excel(self.file_path)\n",
        "    TEST = TEST.rename(columns={'Query':'Question'})\n",
        "    print(TEST.shape)\n",
        "  def generate_vectors(self):\n",
        "    self.sentence_list = TEST.Question.values.tolist()\n",
        "    model = SentenceTransformer('sentence-transformers/distilbert-base-nli-mean-tokens')\n",
        "    embeddings = model.encode(self.sentence_list)\n",
        "    print(len(embeddings))\n",
        "    self.train_vector = pd.DataFrame(np.array(embeddings))\n",
        "    print(self.train_vector.shape)\n",
        "  def load_and_predict(self):\n",
        "    loaded_model = pickle.load(open(self.model_path , 'rb'))\n",
        "    predictions = loaded_model.predict(self.train_vector)\n",
        "    print(len(predictions))\n",
        "    TEST['Predicted Labels'] = predictions\n",
        "    return TEST\n",
        " \n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IA0bLyhIGzk",
        "outputId": "b858000d-04e7-4a59-ff40-7ed33e015ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_path = \"/content/TestSet_QueryClassification.xlsx\"\n",
        "model_path = \"/content/drive/MyDrive/AV_Hack/Logistic_regression.pkl\"\n",
        "testdata = process_test_data(file_path,model_path)\n",
        "testdata.read_data()\n",
        "testdata.generate_vectors()\n",
        "df= testdata.load_and_predict()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 3)\n",
            "20\n",
            "(20, 768)\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfqwNNLGw2HI",
        "outputId": "91fd0b68-d468-4d67-8073-6e840e6032ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, ..., 5, 5, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}